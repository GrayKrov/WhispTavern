# robots.txt — WhispTavern
# Purpose:
# - Allow normal search + social previews
# - Block /internal/ and other private-ish areas
# - Opt out of AI model training crawlers
# - Throttle or block aggressive SEO/spam bots
# - Provide sitemap

# ─────────────────────────────────────────────────────────────────────────────
# Canonical sitemap
Sitemap: https://whisptavern.com/sitemap.xml

# ─────────────────────────────────────────────────────────────────────────────
# Default policy for most crawlers
User-agent: *
# Keep private areas out of the index
Disallow: /internal/
# If you add any server-side endpoints later, list them here:
Disallow: /api/
Disallow: /admin/
# Prevent infinite URL variants (tracking params, etc.)
Disallow: /*?*utm_
Disallow: /*?*ref=
Disallow: /*?*session=
# Polite crawl throttle (Google ignores, Bing respects)
Crawl-delay: 10

# ─────────────────────────────────────────────────────────────────────────────
# Allow social preview bots to fetch pages (for rich link cards)
User-agent: Twitterbot
Allow: /
User-agent: Slackbot
Allow: /
User-agent: Discordbot
Allow: /
User-agent: LinkedInBot
Allow: /
User-agent: facebookexternalhit
Allow: /

# ─────────────────────────────────────────────────────────────────────────────
# Opt-out of AI/model training crawlers
# (These respect robots.txt and won’t use your content for training if blocked)
User-agent: GPTBot
Disallow: /
User-agent: Google-Extended
Disallow: /
User-agent: CCBot
Disallow: /
User-agent: ClaudeBot
Disallow: /
User-agent: Claude-Web
Disallow: /
User-agent: PerplexityBot
Disallow: /
User-agent: Bytespider
Disallow: /
User-agent: Amazonbot
Disallow: /
# If you prefer, you can *explicitly* allow previews for Discord/Twitter/etc. above
# while still blocking AI training here.

# ─────────────────────────────────────────────────────────────────────────────
# Optional: block or throttle common SEO/spam crawlers (saves bandwidth)
# If you care about these tools seeing your site, comment these out.
User-agent: AhrefsBot
Disallow: /
User-agent: SemrushBot
Disallow: /
User-agent: MJ12bot
Disallow: /
User-agent: DotBot
Disallow: /
User-agent: PetalBot
Disallow: /
User-agent: YandexBot
Crawl-delay: 10

# ─────────────────────────────────────────────────────────────────────────────
# Staging/Preview recommendation (use in preview only — NOT in production):
# User-agent: *
# Disallow: /

# ─────────────────────────────────────────────────────────────────────────────
# Notes:
# - robots.txt is advisory. Bad actors can ignore it. For stronger protection,
#   use Cloudflare Firewall Rules/Rate Limiting to block unwanted user agents.
# - We purposely do NOT block JS/CSS/image assets here to avoid breaking search
#   engine rendering of pages.
